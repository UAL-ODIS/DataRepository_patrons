#!/user/bin/env python

from os import path, chmod
from os import mkdir

from datetime import date

import configparser
import argparse

from requiam import ldap_query
from requiam.grouper_query import grouper_delta_user
from requiam.logger import LogClass, get_user_hostname
from requiam import TimerClass
from requiam.manual_override import ManualOverride, get_current_groups
from requiam.grouper_admin import GrouperAPI

# Version and branch info
from requiam import __version__
from requiam.git_info import get_active_branch_name, get_latest_commit
from requiam import __file__ as library_path

today = date.today()

library_root_path = path.dirname(path.dirname(library_path))  # Retrieve parent directory to requiam


if __name__ == '__main__':
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Command-line driver for simple user EDS updates.')
    parser.add_argument('--netid', required=True,
                        help='''NetIDs for user. Comma separated for multiple users.
                                Alternatively path to .txt file that contains users (single entry per line).''')
    parser.add_argument('--config', required=True, help='path to configuration file')
    parser.add_argument('--persistent_path', required=True, help='full parent path for logs')
    parser.add_argument('--ldap_host', help='LDAP host')
    parser.add_argument('--ldap_base_dn', help='base DN for LDAP bind and query')
    parser.add_argument('--ldap_user', help='user name for LDAP login')
    parser.add_argument('--ldap_password', help='password for LDAP login')
    parser.add_argument('--grouper_host', help='Grouper host')
    parser.add_argument('--grouper_base_path', help='base path for Grouper API')
    parser.add_argument('--grouper_user', help='user name for Grouper login')
    parser.add_argument('--grouper_password', help='password for Grouper login')
    parser.add_argument('--batch_size', help='synchronization batch size')
    parser.add_argument('--batch_timeout', help='synchronization batch timeout in seconds')
    parser.add_argument('--batch_delay', help='delay between batches in seconds')
    parser.add_argument('--portal', help='Specifies portal change')
    parser.add_argument('--quota', help='Specifies quota change')
    parser.add_argument('--portal_file', help='filename for manual-override portal file')
    parser.add_argument('--quota_file', help='filename for manual-override quota file')
    parser.add_argument('--sync', action='store_true', help='perform synchronization')
    parser.add_argument('--sync_max', help='maximum membership delta to allow when synchronizing')
    parser.add_argument('--active_remove', action='store_true', help='Remove membership in figshare:active group')
    parser.add_argument('--debug', action='store_true', help='turn on debug logging')
    args = parser.parse_args()

    branch_name = get_active_branch_name(library_root_path)
    git_commit, git_short_commit = get_latest_commit(library_root_path)

    banner_message = f"""
    This is the command-line tool that enable manual updates to Grouper membership.

    ReQUIAM active branch: {branch_name}
    ReQUIAM version: {__version__}
    ReQUIAM commit hash: {git_short_commit}
    Created by Chun Ly
    Issues? Submit a GitHub ticket: https://github.com/ualibraries/ReQUIAM/issues/new
    """
    print(banner_message)

    main_timer = TimerClass()
    main_timer._start()

    config = configparser.ConfigParser()
    config.read(args.config)

    # Define logfile
    log_dir = path.join(args.persistent_path, config.get('global', 'log_dir'))

    if not path.exists(log_dir):
        mkdir(log_dir)
    logfile = f"user_update.{today.strftime('%Y-%m-%d')}.log"

    log = LogClass(log_dir, logfile).get_logger()

    log.info("*******************************")
    log.info("Started user_update script ... ")
    log.debug(f"ReQUIAM active branch: {branch_name}")
    log.debug(f"ReQUIAM version: {__version__} ({git_short_commit})")
    log.debug(f"ReQUIAM commit hash: {git_commit}")

    # Retrieve username, hostname, IP
    sys_info = get_user_hostname()
    log.debug(f"username : {sys_info['user']}")
    log.debug(f"hostname : {sys_info['hostname']}")
    log.debug(f"IP Addr  : {sys_info['ip']}")
    log.debug(f"Op. Sys. : {sys_info['os']}")

    cred_err = 0
    vargs = vars(args)
    for p in ['netid', 'persistent_path', 'ldap_host', 'ldap_base_dn', 'ldap_user', 'ldap_password',
              'grouper_host', 'grouper_base_path', 'grouper_user', 'grouper_password',
              'batch_size', 'batch_timeout', 'batch_delay', 'portal', 'quota',
              'portal_file', 'quota_file', 'sync_max', 'active_remove']:

        if (p in vargs) and (vargs[p] is not None):
            vargs[p] = vargs[p]
        elif (p in config['global']) and (config['global'][p] is not None) and \
                (config['global'][p] != "***override***"):
            vargs[p] = config['global'][p]
        else:
            vargs[p] = '(unset)'

        if p in ['ldap_user', 'ldap_password', 'grouper_user', 'grouper_password']:
            if vargs[p] is '(unset)':
                log.info('   {0: >17} = (unset)'.format(p))
                cred_err += 1
            else:
                log.info('   {0: >17} = (set)'.format(p))
        else:
            log.info('   {0: >17} = {1:}'. format(p, vargs[p]))

    if cred_err:
        log.warning("Not all credentials available!")
        log.warning("Exiting")
        raise ValueError

    log.info('     sync = %s', args.sync)
    log.info('    debug = %s', args.debug)

    ldap_dict = dict(ldap_host=vargs['ldap_host'],
                     ldap_base_dn=vargs['ldap_base_dn'],
                     ldap_user=vargs['ldap_user'],
                     ldap_password=vargs['ldap_password'])

    grouper_dict = dict(grouper_host=vargs['grouper_host'],
                        grouper_base_path=vargs['grouper_base_path'],
                        grouper_user=vargs['grouper_user'],
                        grouper_password=vargs['grouper_password'])

    delta_dict = dict(batch_size=int(vargs['batch_size']),
                      batch_timeout=int(vargs['batch_timeout']),
                      batch_delay=int(vargs['batch_delay']),
                      sync_max=int(vargs['sync_max']))

    # Manual override class
    mo = ManualOverride(vargs['portal_file'], vargs['quota_file'], log=log)

    # Initiate LDAP connection
    ldc = ldap_query.LDAPConnection(**ldap_dict, log=log)

    if '.txt' in vargs['netid'][-4:]:
        # Read in text file with list of users
        log.info(f"Reading : {vargs['netid']}")
        with open(vargs['netid']) as f:
            netid_list = f.read().splitlines()
        f.close()
        log.info(f"List of input users: {netid_list}")
    else:
        # Separate comma-separated list of users
        netid_list = vargs['netid'].split(',')

    netid_set = sorted(set(netid_list), key=netid_list.index)
    num_netid = len(netid_set)

    # Get uaid based on NetID (uid)
    clean_uaid_list  = []
    clean_netid_list = []
    for netid in netid_set:
        uid_query = ldap_query.uid_query(netid)
        user_uaid = ldap_query.ldap_search(ldc, uid_query)
        if len(user_uaid) == 0:
            log.warning(f"netid not found! {netid}")
        else:
            log.info(f" uaid for {netid} : {list(user_uaid)[0]}")
            clean_uaid_list.append(list(user_uaid)[0])
            clean_netid_list.append(netid)

    if len(clean_uaid_list) == 0:
        log.warning(f"No netid's to work with")
        raise ValueError

    # Grouper API tool
    ga = GrouperAPI(**grouper_dict, log=log)

    # Check to see if portal exists on Grouper before proceeding
    portal_check = True
    if vargs['portal'] != '(unset)' and vargs['portal'] != 'root':
        portal_check = ga.check_group_exists(vargs['portal'], 'portal')

        if not portal_check:
            log.warning("portal not found on Grouper!")

    # Check to see if quota exists on Grouper before proceeding
    quota_check = True
    if vargs['quota'] != '(unset)' and vargs['quota'] != 'root':
        quota_check = ga.check_group_exists(vargs['quota'], 'quota')

        if not quota_check:
            log.warning("quota not found on Grouper!")

    # Raise error if either Grouper checks fails
    if not portal_check or not quota_check:
        raise SystemError

    # Initialized nested dictionary
    current_dict = dict()
    current_dict['active'] = {'uaid': [], 'netid': []}
    current_dict['not_active'] = {'uaid': [], 'netid': []}

    current_dict['summary'] = {'active': 0}
    if vargs['portal'] != '(unset)':
        current_dict['summary']['portal'] = 0

        current_dict['portal'] = {'uaid': [], 'netid': []}
        current_dict['not_portal'] = {'uaid': [], 'netid': []}
    if vargs['quota'] != '(unset)':
        current_dict['summary']['quota'] = 0

        current_dict['quota'] = {'uaid': [], 'netid': []}
        current_dict['not_quota'] = {'uaid': [], 'netid': []}

    # Retrieve ismemberof figshare information
    # Populate current_dict
    for netid, uaid in zip(clean_netid_list, clean_uaid_list):
        current_dict[netid] = get_current_groups(netid, ldap_dict, log=log,
                                                 verbose=False)
        if current_dict[netid]['active']:
            current_dict['summary']['active'] += 1
            current_dict['active']['uaid'] += [uaid]
            current_dict['active']['netid'] += [netid]
        else:
            current_dict['not_active']['uaid'] += [uaid]
            current_dict['not_active']['netid'] += [netid]

        if vargs['portal'] != '(unset)':
            if current_dict[netid]['portal'] == vargs['portal']:
                current_dict['summary']['portal'] += 1

                current_dict['portal']['uaid'] += [uaid]
                current_dict['portal']['netid'] += [netid]
            else:
                current_dict['not_portal']['uaid'] += [uaid]
                current_dict['not_portal']['netid'] += [netid]

        if vargs['quota'] != '(unset)':
            if current_dict[netid]['quota'] == vargs['quota']:
                current_dict['summary']['quota'] += 1

                current_dict['quota']['uaid'] += [uaid]
                current_dict['quota']['netid'] += [netid]
            else:
                current_dict['not_quota']['uaid'] += [uaid]
                current_dict['not_quota']['netid'] += [netid]

    # Provide general information about active status
    if len(current_dict['active']['netid']) == 0:
        log.info("None of the supplied users are active")
    if len(current_dict['not_active']['netid']) == 0:
        log.info("All users are active")

    if len(current_dict['active']['netid']) > 0:
        log.info(f"List of users that are active : {current_dict['active']['netid']}")
    if len(current_dict['not_active']['netid']) > 0:
        log.info(f"List of users that are NOT active : {current_dict['not_active']['netid']}")

    # figshare:active update
    if not vargs['active_remove']:
        if len(current_dict['not_active']['netid']) > 0:
            log.info("Adding to figshare:active group")

            d = grouper_delta_user('active', '',
                                   current_dict['not_active']['netid'],
                                   set(current_dict['not_active']['uaid']),
                                   'add', grouper_dict, delta_dict,
                                   sync=args.sync, log=None)
        else:
            log.info("All users are member of figshare:active. No need to add")
    else:
        if len(current_dict['active']['netid']) > 0:
            log.info("Removing from figshare:active group")

            d = grouper_delta_user('active', '',
                                   current_dict['active']['netid'],
                                   set(current_dict['active']['uaid']),
                                   'remove', grouper_dict, delta_dict,
                                   sync=args.sync, log=None)
        else:
            log.info("All users not a member of figshare:active. No need to remove")

    # Portal update
    if vargs['portal'] != '(unset)':
        if len(current_dict['not_portal']['netid']) == 0:
            log.warning(f"All users are member of portal:{vargs['portal']}. No need to add")
        else:
            # First remove from current portal group
            not_portal_netid = current_dict['not_portal']['netid']
            not_portal_uaid = current_dict['not_portal']['uaid']

            for i in range(len(not_portal_netid)):  # Loop over each case
                current_portal = current_dict[not_portal_netid[i]]['portal']
                if current_portal == 'root':
                    log.info(f"{not_portal_netid[i]} not assigned to a portal. Skipping removal")
                else:
                    log.info(f"Removing {not_portal_netid[i]} from current {current_portal} portal")

                    d = grouper_delta_user(current_portal, 'portal',
                                           not_portal_netid[i], {not_portal_uaid[i]},
                                           'remove', grouper_dict, delta_dict,
                                           sync=args.sync, log=None)

            # Add to new portal group
            if vargs['portal'] != 'root':
                log.info(f"Adding to {vargs['portal']} portal")

                d = grouper_delta_user(vargs['portal'], 'portal',
                                       current_dict['not_portal']['netid'],
                                       current_dict['not_portal']['uaid'],
                                       'add', grouper_dict, delta_dict, mo=mo,
                                       sync=args.sync, log=None)
            else:
                # Remove entry from manual CSV file for 'root' case
                if args.sync:
                    # Update of df only needed since there's not root portal to add too
                    mo.update_dataframe(current_dict['not_portal']['netid'],
                                        current_dict['not_portal']['uaid'],
                                        vargs['portal'], 'portal')
                else:
                    log.info('dry run, not updating portal dataframe')

    # Quota update
    if vargs['quota'] != '(unset)':
        if len(current_dict['not_quota']['netid']) == 0:
            log.warning(f"All users are member of quota:{vargs['quota']}. No need to add")
        else:
            # First remove from current quota group
            not_quota_netid = current_dict['not_quota']['netid']
            not_quota_uaid = current_dict['not_quota']['uaid']

            for i in range(len(not_quota_netid)):
                current_quota = current_dict[not_quota_netid[i]]['quota']
                if current_quota == 'root':
                    log.info(f"{not_quota_netid[i]} not assigned to a quota. Skipping removal")
                else:
                    log.info(f"Removing {not_quota_netid[i]} from current {current_quota} quota")

                    d = grouper_delta_user(current_quota, 'quota',
                                           not_quota_netid[i], {not_quota_uaid[i]},
                                           'remove', grouper_dict, delta_dict,
                                           sync=args.sync, log=None)

            # Add to new quota group
            if vargs['quota'] != 'root':
                log.info(f"Adding to {vargs['quota']} quota")

                d = grouper_delta_user(vargs['quota'], 'quota',
                                       current_dict['not_quota']['netid'],
                                       current_dict['not_quota']['uaid'],
                                       'add', grouper_dict, delta_dict,
                                       mo=mo, sync=args.sync, log=None)
            else:
                # Remove entry from manual CSV file for 'root' case
                if args.sync:
                    # Update of df only needed since there's not root portal to add too
                    mo.update_dataframe(current_dict['not_quota']['netid'],
                                        current_dict['not_quota']['uaid'],
                                        vargs['quota'], 'quota')
                else:
                    log.info('dry run, not updating portal dataframe')

    main_timer._stop()
    log.info(main_timer.format)

    log.info("*******************************")
    log.info("Exit 0")

    chmod(path.join(log_dir, logfile), mode=0o666)
