#!/user/bin/env python

from os import path, chmod
from os import mkdir

import pandas as pd

from datetime import date

import configparser
import argparse

import ast

from requiam import ldap_query
from requiam import grouper_query
from requiam.grouper_admin import GrouperAPI
from requiam import delta
from requiam import quota
from requiam.logger import LogClass, get_user_hostname, pandas_write_buffer
from requiam import TimerClass
from requiam import manual_override

# Version and branch info
from requiam import __version__
from requiam.git_info import get_active_branch_name, get_latest_commit
from requiam import __file__ as library_path

today = date.today()

library_root_path = path.dirname(path.dirname(library_path))  # Retrieve parent directory to requiam


if __name__ == '__main__':
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Command-line driver for figshare patron management.')
    parser.add_argument('--config', required=True, help='path to configuration file')
    parser.add_argument('--persistent_path', required=True, help='full parent path for logs')
    parser.add_argument('--ldap_host', help='LDAP host')
    parser.add_argument('--ldap_base_dn', help='base DN for LDAP bind and query')
    parser.add_argument('--ldap_user', help='user name for LDAP login')
    parser.add_argument('--ldap_password', help='password for LDAP login')
    parser.add_argument('--grouper_host', help='Grouper host')
    parser.add_argument('--grouper_base_path', help='base path for Grouper API')
    parser.add_argument('--grouper_user', help='user name for Grouper login')
    parser.add_argument('--grouper_password', help='password for Grouper login')
    parser.add_argument('--batch_size', help='synchronization batch size')
    parser.add_argument('--batch_timeout', help='synchronization batch timeout in seconds')
    parser.add_argument('--batch_delay', help='delay between batches in seconds')
    parser.add_argument('--portal', action='store_true', help='perform portal queries')
    parser.add_argument('--quota', action='store_true', help='perform quota queries')
    parser.add_argument('--test', action='store_true', help='perform test query')
    parser.add_argument('--test_reverse', action='store_true', help='reverse test query (i.e., remove from Grouper)')
    parser.add_argument('--portal_file', help='filename for manual-override portal file')
    parser.add_argument('--quota_file', help='filename for manual-override quota file')
    parser.add_argument('--sync', action='store_true', help='perform synchronization')
    parser.add_argument('--sync_max', help='maximum membership delta to allow when synchronizing')
    parser.add_argument('--debug', action='store_true', help='turn on debug logging')
    args = parser.parse_args()

    branch_name = get_active_branch_name(library_root_path)
    git_commit, git_short_commit = get_latest_commit(library_root_path)

    banner_message = f"""
    This is the command-line tool that automates Grouper patron management.
    A full execution will update users' ismemberof attributes for:
     1. figshare:portal (--portal set) and
     2. figshare:quota  (--quota set)

    ReQUIAM active branch: {branch_name}
    ReQUIAM version: {__version__}
    ReQUIAM commit hash: {git_short_commit}
    Created by Chun Ly
    Issues? Submit a GitHub ticket: https://github.com/ualibraries/ReQUIAM/issues/new
    """
    print(banner_message)

    main_timer = TimerClass()
    main_timer._start()

    config = configparser.ConfigParser()
    config.read(args.config)

    # Define logfile
    log_dir = path.join(args.persistent_path, config.get('global', 'log_dir'))

    if not path.exists(log_dir):
        mkdir(log_dir)
    logfile_prefix = config.get('global', 'logfile_prefix')
    logfile = f'{logfile_prefix}.{today.strftime("%Y-%m-%d")}.log'

    log_filename = path.join(log_dir, logfile)  # Full log filename path
    log = LogClass(log_dir, logfile).get_logger()

    log.info("******************************")
    log.info("Started script_run script ... ")
    log.debug(f"ReQUIAM active branch: {branch_name}")
    log.debug(f"ReQUIAM version: {__version__} ({git_short_commit})")
    log.debug(f"ReQUIAM commit hash: {git_commit}")

    # Retrieve username, hostname, IP
    sys_info = get_user_hostname()
    log.debug(f"username : {sys_info['user']}")
    log.debug(f"hostname : {sys_info['hostname']}")
    log.debug(f"IP Addr  : {sys_info['ip']}")
    log.debug(f"Op. Sys. : {sys_info['os']}")

    cred_err = 0
    vargs = vars(args)
    for p in ['persistent_path', 'ldap_host', 'ldap_base_dn', 'ldap_user', 'ldap_password',
              'grouper_host', 'grouper_base_path', 'grouper_user', 'grouper_password',
              'batch_size', 'batch_timeout', 'batch_delay', 'portal', 'quota',
              'portal_file', 'quota_file', 'test', 'test_reverse', 'sync_max']:

        if (p in vargs) and (vargs[p] is not None):
            vargs[p] = vargs[p]
        elif (p in config['global']) and (config['global'][p] is not None) and \
                (config['global'][p] != "***override***"):
            vargs[p] = config['global'][p]
        else:
            vargs[p] = '(unset)'

        if p in ['ldap_user', 'ldap_password', 'grouper_user', 'grouper_password']:
            if vargs[p] is '(unset)':
                log.info('   {0: >17} = (unset)'.format(p))
                cred_err += 1
            else:
                log.info('   {0: >17} = (set)'.format(p))
        else:
            log.info('   {0: >17} = {1:}'. format(p, vargs[p]))

    if vargs['test'] and vargs['test_reverse']:
        log.warning("Cannot provide --test and --test_reverse")
        log.warning("Exiting")
        raise ValueError

    if cred_err:
        log.warning("Not all credentials available!")
        log.warning("Exiting")
        raise ValueError

    log.info('     sync = %s', args.sync)
    log.info('    debug = %s', args.debug)

    try:
        mo = manual_override.ManualOverride(vargs['portal_file'], vargs['quota_file'],
                                            log=log)
        mo_status = True
    except ValueError:
        log.warning("Unable to find manual CSV configuration files")
        log.warning("Skipping manual handling")
        mo_status = False

    # Initiate LDAP connection
    ldc = ldap_query.LDAPConnection(ldap_host=vargs['ldap_host'],
                                    ldap_base_dn=vargs['ldap_base_dn'],
                                    ldap_user=vargs['ldap_user'],
                                    ldap_password=vargs['ldap_password'],
                                    log=log)

    grouper_dict = dict(grouper_host=vargs['grouper_host'],
                        grouper_base_path=vargs['grouper_base_path'],
                        grouper_user=vargs['grouper_user'],
                        grouper_password=vargs['grouper_password'])

    delta_dict = dict(batch_size=int(vargs['batch_size']),
                      batch_timeout=int(vargs['batch_timeout']),
                      batch_delay=int(vargs['batch_delay']),
                      sync_max=int(vargs['sync_max']))

    # This is for checking whether the group exists
    ga = GrouperAPI(**grouper_dict, grouper_production=True, log=log)

    # Perform EDS-Grouper synchronization for figshare research portals
    if args.portal:
        portal_timer = TimerClass()
        portal_timer._start()

        # Read in CSV file
        csv_url = config.get('global', 'csv_url')
        df = pd.read_csv(csv_url)

        unique_portals = df['Sub-portals'].unique()
        unique_portals_name = df['Research Themes'].unique()

        # Loop over sub-portals
        for portal, portal_name in zip(unique_portals, unique_portals_name):
            log.info("Working on {} ({}) portal".format(portal_name, portal))

            group_check = ga.check_group_exists(portal, 'portal')
            if not group_check:
                log.warning(f"!!! Grouper portal NOT found : {portal} !!!")
            else:
                log.info(f"Grouper portal exists : {portal}")

                df_sub = df.loc[df['Sub-portals'] == portal]

                pandas_write_buffer(df_sub, log_filename)

                # Get list of org codes for [portal]
                org_code_list = df_sub['Org Code']

                org_name_list = df_sub['Departments/Colleges/Labs/Centers']

                # LDAP query to retrieve members
                ldap_queries = ldap_query.ual_ldap_queries(org_code_list)

                ldap_members = ldap_query.ldap_search(ldc, ldap_queries)

                # Update based on CSV manual input files
                if mo_status:
                    ldap_members = mo.identify_changes(ldap_members, portal, 'portal')
                log.info(" EDS size {}".format(len(ldap_members)))

                # Grouper query
                grouper_portal = grouper_query.figshare_group(portal, 'portal')
                gq = grouper_query.GrouperQuery(**grouper_dict,
                                                grouper_group=grouper_portal, log=log)
                log.info(" Grouper size {}".format(len(gq.members)))

                d = delta.Delta(ldap_members=ldap_members,
                                grouper_query_instance=gq,
                                **delta_dict,
                                log=log)

                log.info('ldap and grouper have {} members in common'.format(len(d.common)))
                log.info('synchronization will drop {} entries from grouper group'.format(len(d.drops)))
                log.info('synchronization will add {} entries to grouper group'.format(len(d.adds)))

                if args.sync:
                    log.info('synchronizing ...')
                    d.synchronize()
                else:
                    log.info('dry run, not performing synchronization')

        portal_timer._stop()
        log.info("PORTAL : " + portal_timer.format)

    # Perform EDS-Grouper synchronization for figshare quota
    if args.quota:
        quota_timer = TimerClass()
        quota_timer._start()

        quota_list  = ast.literal_eval(config['global']['quota_list'])
        quota_class = ast.literal_eval(config['global']['quota_class'])

        for q, c in zip(quota_list, quota_class):
            log.info("Working on {} quota : {} bytes".format(c, q))

            group_check = ga.check_group_exists(q, 'quota')
            if not group_check:
                log.warning(f"!!! Grouper quota NOT found : {q} !!!")
            else:
                log.info(f"Grouper quota exists : {q}")

                # LDAP query to retrieve members
                ldap_queries = quota.ual_ldap_quota_query(c)

                ldap_members = ldap_query.ldap_search(ldc, ldap_queries)

                # Update based on CSV manual input files
                if mo_status:
                    ldap_members = mo.identify_changes(ldap_members, q, 'quota')
                log.info(" EDS size {}".format(len(ldap_members)))

                # Grouper query
                grouper_quota = grouper_query.figshare_group(q, 'quota')
                gq = grouper_query.GrouperQuery(**grouper_dict,
                                                grouper_group=grouper_quota)
                log.info(" Grouper size {}".format(len(gq.members)))

                # Delta between LDAP and Grouper
                d = delta.Delta(ldap_members=ldap_members,
                                grouper_query_instance=gq,
                                **delta_dict,
                                log=log)

                log.info('ldap and grouper have {} members in common'.format(len(d.common)))
                log.info('synchronization will drop {} entries from grouper group'.format(len(d.drops)))
                log.info('synchronization will add {} entries to grouper group'.format(len(d.adds)))

                if args.sync:
                    log.info('synchronizing ...')
                    d.synchronize()
                else:
                    log.info('dry run, not performing synchronization')

        quota_timer._stop()
        log.info("QUOTA : "+quota_timer.format)

    # Perform EDS-Grouper synchronization for simple test
    if args.test or args.test_reverse:
        test_timer = TimerClass()
        test_timer._start()

        log.info("Working on test sync")

        # LDAP query to retrieve members
        test_uid = config.get('global', 'uid')
        ldap_queries = ldap_query.uid_query(test_uid)
        log.info(" test account : {}".format(test_uid))

        ldap_members = set()
        if args.test:
            ldap_members = ldap_query.ldap_search(ldc, ldap_queries)
            log.info(" EDS size {}".format(len(ldap_members)))
        if args.test_reverse:
            log.info(" Providing empty member list")

        grouper_test = grouper_query.figshare_group('test', '')
        gq = grouper_query.GrouperQuery(**grouper_dict, grouper_group=grouper_test, log=None)
        log.info(" Grouper size {}".format(len(gq.members)))

        # Delta between LDAP and Grouper
        d = delta.Delta(ldap_members=ldap_members, grouper_query_instance=gq,
                        **delta_dict, log=log)

        log.info('ldap and grouper have {} members in common'.format(len(d.common)))
        log.info('synchronization will drop {} entries from grouper group'.format(len(d.drops)))
        log.info('synchronization will add {} entries to grouper group'.format(len(d.adds)))

        if args.sync:
            log.info('synchronizing ...')
            d.synchronize()
        else:
            log.info('dry run, not performing synchronization')

        test_timer._stop()
        log.info("TEST_SYNC : "+test_timer.format)

    main_timer._stop()
    log.info(main_timer.format)

    log.info("******************************")
    log.info("Exit 0")

    chmod(path.join(log_dir, logfile), mode=0o666)
